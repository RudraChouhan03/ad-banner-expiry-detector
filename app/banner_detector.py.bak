import os
import cv2
import numpy as np
from typing import List, Tuple, Dict, Any, Optional
import torch
from PIL import Image
import config
from utils import resize_image_for_display, draw_detection_boxes

class BannerDetector:
    """
    Handles banner detection using YOLOv8 model and provides
    functionality for automatic and manual cropping.
    """
    
    def __init__(self, model_path: str = config.YOLO_MODEL_PATH):
        """
        Initialize the banner detector with YOLO model.
        
        Args:
            model_path: Path to trained YOLO model
        """
        self.model_path = model_path  # Store model path
        self.model = None  # Initialize model as None
        self.model_loaded = False  # Flag to track if model is loaded
        
        # Load YOLO model
        self.load_model()
    
    def load_model(self) -> bool:
        """
        Load YOLOv8 model with robust error handling.
        
        Returns:
            bool: True if model loaded successfully, False otherwise
        """
        try:
            # Check if model file exists
            if not os.path.exists(self.model_path):
                print(f"Error: YOLO model file not found at {self.model_path}")
                return False
            
            # Check file size to make sure it's a valid model file
            try:
                file_size = os.path.getsize(self.model_path)
                if file_size < 10000:  # Model files should be at least 10KB
                    print(f"Error: YOLO model file at {self.model_path} appears to be invalid (too small: {file_size} bytes)")
                    return False
                print(f"Model file size: {file_size / (1024*1024):.2f} MB")
            except Exception as e:
                print(f"Warning: Could not check model file size: {e}")
                
            # APPROACH 1: Try loading directly via ultralytics
            try:
                from ultralytics import YOLO
                self.model = YOLO(self.model_path)
                print(f"YOLOv8 model loaded successfully via ultralytics from {self.model_path}")
                self.model_loaded = True
                return True
            except Exception as e:
                print(f"Warning: Could not load with ultralytics YOLO: {e}")
            
            # APPROACH 2: Try with torch.load and weights_only=False
            try:
                import torch
                # For PyTorch 2.6+ compatibility
                if hasattr(torch.serialization, 'add_safe_globals'):
                    try:
                        torch.serialization.add_safe_globals(['ultralytics.nn.tasks.DetectionModel'])
                        print("Added safe globals for PyTorch 2.6+")
                    except Exception as e:
                        print(f"Warning: Could not add safe globals: {e}")
                
                # Try loading with weights_only=False
                try:
                    self.model = torch.load(self.model_path, map_location=torch.device('cpu'), weights_only=False)
                    print(f"YOLOv8 model loaded successfully with weights_only=False from {self.model_path}")
                    self.model_loaded = True
                    return True
                except Exception as e:
                    print(f"Warning: Could not load with weights_only=False: {e}")
            except Exception as e:
                print(f"Warning: Error in torch loading attempt: {e}")
            
            # APPROACH 3: Try PyTorch Hub as last resort
            try:
                import torch
                os.environ['TORCH_HOME'] = os.path.dirname(self.model_path)
                os.environ['TORCH_OFFLINE'] = '1'  # Try to avoid internet requests
                
                self.model = torch.hub.load('ultralytics/yolov8', 'custom', path=self.model_path, trust_repo=True)
                self.model.conf = config.YOLO_CONFIDENCE_THRESHOLD
                self.model.iou = config.YOLO_IOU_THRESHOLD
                
                print(f"YOLOv8 model loaded successfully via PyTorch Hub from {self.model_path}")
                self.model_loaded = True
                return True
            except Exception as e:
                print(f"Failed to load YOLO model via PyTorch Hub: {e}")
            
            # If all approaches failed
            self.model = None
            self.model_loaded = False
            return False
            
        except Exception as e:
            print(f"Failed to load YOLO model: {e}")
            self.model = None
            self.model_loaded = False
            return False
            
    def detect_banners(self, image_path: str) -> Dict[str, Any]:
        """
        Detect banners in an image using the YOLOv8 model.
        
        Args:
            image_path: Path to the image
            
        Returns:
            Dictionary with detection results
        """
        # Load image first to avoid unnecessary model loading if image is invalid
        try:
            image = cv2.imread(image_path)  # Read image
            if image is None:
                return {
                    'success': False,  # Detection failed
                    'error': f"Could not load image: {image_path}",  # Error message
                    'boxes': [],  # Empty boxes list
                    'image': None,  # No image
                    'count': 0  # Zero detections
                }
        except Exception as e:
            return {
                'success': False,  # Detection failed
                'error': f"Error loading image: {e}",  # Error message
                'boxes': [],  # Empty boxes list
                'image': None,  # No image
                'count': 0  # Zero detections
            }
            
        # Check if YOLO model is loaded, otherwise use fallback detection
        if not self.model_loaded:
            print("Using fallback detection method because YOLO model is not loaded")
            return self._fallback_detection(image)
        
        # Use YOLO model for detection
        try:
            results = self.model(image)  # Run inference
            boxes = []
            
            # Process results
            if hasattr(results, 'xyxy') and len(results.xyxy[0]) > 0:
                # Process old format results
                for box in results.xyxy[0].cpu().numpy():
                    x1, y1, x2, y2, confidence, class_id = box
                    boxes.append({
                        'box': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(confidence),
                        'class_id': int(class_id)
                    })
            elif hasattr(results, 'boxes') and len(results.boxes) > 0:
                # Process new format results
                for box in results.boxes.cpu().numpy():
                    x1, y1, x2, y2 = box.xyxy[0]
                    confidence = box.conf[0]
                    class_id = box.cls[0]
                    boxes.append({
                        'box': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(confidence),
                        'class_id': int(class_id)
                    })
            
            # Create annotated image for visualization
            annotated_img = draw_detection_boxes(image.copy(), boxes)
            
            return {
                'success': True,  # Detection successful
                'boxes': boxes,  # Detected boxes
                'image': annotated_img,  # Annotated image
                'count': len(boxes),  # Number of detections
                'method': 'yolo'  # Detection method used
            }
        except Exception as e:
            print(f"YOLO detection failed, falling back to basic detection: {e}")
            return self._fallback_detection(image)
            
    def _fallback_detection(self, image: np.ndarray) -> Dict[str, Any]:
        """
        Simple fallback banner detection when YOLO model is not available.
        
        Uses basic image processing techniques to find potential banner areas.
        
        Args:
            image: Input image as numpy array
            
        Returns:
            Dictionary with detection results
        """
        Uses basic image processing techniques to find potential banner areas.
        
        Args:
            image: Input image as numpy array
            
        Returns:
            Dictionary with detection results
        """
        try:
            # Create a copy of the image
            img_copy = image.copy()
            
            # Convert to grayscale
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Apply Gaussian blur to reduce noise
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Apply Canny edge detection
            edges = cv2.Canny(blurred, 50, 150)
            
            # Find contours in the edge image
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # Filter contours by size (potential banners)
            boxes = []
            confidences = []
            min_area = image.shape[0] * image.shape[1] * 0.01  # Minimum 1% of image area
            max_area = image.shape[0] * image.shape[1] * 0.5   # Maximum 50% of image area
            
            for contour in contours:
                # Get bounding box
                x, y, w, h = cv2.boundingRect(contour)
                area = w * h
                
                # Check if contour could be a banner
                if min_area < area < max_area and w > h:  # Wider than tall
                    boxes.append((x, y, x+w, y+h))
                    confidences.append(0.5)  # Default confidence
            
            # Merge overlapping boxes
            if boxes:
                boxes = self._merge_overlapping_boxes(boxes)
            
            # Draw boxes on image
            annotated_image = draw_detection_boxes(
                image, boxes,
                labels=["Potential Banner" for _ in boxes]
            )
            
            return {
                'success': True,
                'boxes': boxes,
                'confidences': confidences,
                'image': image,
                'annotated_image': annotated_image,
                'count': len(boxes)
            }
            
        except Exception as e:
            print(f"Error in fallback detection: {e}")
            return {
                'success': False,
                'error': f"Fallback detection failed: {e}",
                'boxes': [],
                'image': image,
                'count': 0
            }
    
    def _merge_overlapping_boxes(self, boxes: List[Tuple[int, int, int, int]]) -> List[Tuple[int, int, int, int]]:
        """
        Merge overlapping bounding boxes.
        
        Args:
            boxes: List of bounding boxes as (x1, y1, x2, y2)
            
        Returns:
            List of merged bounding boxes
        """
        if not boxes:
            return []
            
        # Sort boxes by x1 coordinate
        boxes = sorted(boxes, key=lambda box: box[0])
        
        merged_boxes = [boxes[0]]
        
        for box in boxes[1:]:
            last_box = merged_boxes[-1]
            
            # Check if boxes overlap
            if box[0] <= last_box[2]:
                # Merge boxes
                merged_boxes[-1] = (
                    min(last_box[0], box[0]),
                    min(last_box[1], box[1]),
                    max(last_box[2], box[2]),
                    max(last_box[3], box[3])
                )
            else:
                # Add new box
                merged_boxes.append(box)
                
        return merged_boxes
    
    def crop_banners(self, detection_results: Dict[str, Any], output_dir: str = config.AUTO_CROPS_DIR) -> List[Dict[str, Any]]:
        """
        Crop detected banners from image and save to output directory.
        
        Args:
            detection_results: Detection results from detect_banners
            output_dir: Directory to save cropped banners
            
        Returns:
            List of dictionaries with crop information
        """
        # Check if detection was successful
        if not detection_results.get('success', False):
            return []  # Return empty list if detection failed
            
        # Get image and boxes
        image = detection_results['image']  # Get original image
        boxes = detection_results['boxes']  # Get bounding boxes
        
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)  # Create directory
        
        # Generate base filename from timestamp
        base_filename = f"banner_{int(cv2.getTickCount())}"  # Use tick count as unique ID
        
        # Crop and save each banner
        crops = []  # List to store crop information
        
        for i, (x1, y1, x2, y2) in enumerate(boxes):
            # Apply some padding to the crop (5% on each side)
            h, w = image.shape[:2]  # Get image dimensions
            
            # Calculate padding
            pad_x = int((x2 - x1) * 0.05)  # 5% horizontal padding
            pad_y = int((y2 - y1) * 0.05)  # 5% vertical padding
            
            # Apply padding with boundary checks
            x1_pad = max(0, x1 - pad_x)  # Left boundary
            y1_pad = max(0, y1 - pad_y)  # Top boundary
            x2_pad = min(w, x2 + pad_x)  # Right boundary
            y2_pad = min(h, y2 + pad_y)  # Bottom boundary
            
            # Crop banner
            banner_crop = image[y1_pad:y2_pad, x1_pad:x2_pad]  # Crop image
            
            # Skip empty crops
            if banner_crop.size == 0:
                continue  # Skip if crop is empty
                
            # Generate output filename
            crop_filename = f"{base_filename}_{i+1}.jpg"  # Numbered filename
            crop_path = os.path.join(output_dir, crop_filename)  # Full path
            
            # Save cropped banner
            cv2.imwrite(crop_path, banner_crop)  # Save crop to disk
            
            # Add crop info to list
            crops.append({
                'crop_path': crop_path,  # Path where crop is saved
                'original_box': (x1, y1, x2, y2),  # Original bounding box
                'padded_box': (x1_pad, y1_pad, x2_pad, y2_pad),  # Padded bounding box
                'crop_index': i+1,  # Index of this crop
                'filename': crop_filename  # Filename of crop
            })
            
        return crops  # Return list of crops